{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilim-cro/SLM-graph-extractor/blob/main/SLM_graph_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_NThE_ZKNv3"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j langchain-google-vertexai json-repair"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "aLDhFVbFNFLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFacePipeline, HuggingFaceEndpoint\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer"
      ],
      "metadata": {
        "id": "83z7VbEgNG-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "#llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "ZJfi3isVNIW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The name of the person\")\n",
        "    birth_year: float = Field(\n",
        "        ..., description=\"Year the person was born\"\n",
        "    )\n",
        "\n",
        "class Country(BaseModel):\n",
        "    \"\"\"Information about a country.\"\"\"\n",
        "    name: Optional[str] = Field(..., description=\"The name of the country\")\n",
        "\n",
        "\n",
        "\n",
        "class People(BaseModel):\n",
        "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
        "\n",
        "    people: List[Person]\n",
        "\n",
        "class Countries(BaseModel):\n",
        "    \"\"\"Identifying information about all countries in a text.\"\"\"\n",
        "\n",
        "    countries: List[Country]"
      ],
      "metadata": {
        "id": "hKCGUJoPNKDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=People)\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ],
      "metadata": {
        "id": "cOCBTfLRNO92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query =  \"\"\"\n",
        "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
        "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
        "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
        "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "30_eR20-NSA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format_prompt(query=query).to_string())"
      ],
      "metadata": {
        "id": "78R55UWrNSjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = RunnableSequence(prompt | llm)\n",
        "result = chain.invoke({\"query\": query})\n"
      ],
      "metadata": {
        "id": "Exq4Raz3NUkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "-jSIGnK4NWJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_result = parser.parse(result)\n",
        "print(parsed_result)"
      ],
      "metadata": {
        "id": "1SxOwPvRNX5o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}