{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilim-cro/SLM-graph-extractor/blob/Few-shot-learning/SLM_graph_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_NThE_ZKNv3"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j langchain-google-vertexai json-repair"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "aLDhFVbFNFLz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFacePipeline, HuggingFaceEndpoint\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer"
      ],
      "metadata": {
        "id": "83z7VbEgNG-r"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "#llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "ZJfi3isVNIW9",
        "outputId": "c26359a9-559f-4440-c9eb-b44dec757326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the repo ID and parameters for Hugging Face Inference\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    temperature=0.1,\n",
        "    max_length=150  # Adjust as needed\n",
        ")\n",
        "\n",
        "# Create a few-shot prompt with examples\n",
        "prompt = \"\"\"\n",
        "Convert the following sentences into a graph format with entities and relationships.\n",
        "\n",
        "Example 1:\n",
        "Input: Alice gave Bob a book.\n",
        "Output: Entities: [Alice, Bob, book]; Relations: [(Alice, gave, Bob)]\n",
        "\n",
        "Example 2:\n",
        "Input: John sent an email to Mary.\n",
        "Output: Entities: [John, Mary, email]; Relations: [(John, sent, Mary)]\n",
        "\n",
        "Example 3:\n",
        "Input: The dog chased the cat.\n",
        "Output: Entities: [dog, cat]; Relations: [(dog, chased, cat)]\n",
        "\n",
        "Example 4:\n",
        "Input: Emma painted a picture for her mother.\n",
        "Output: Entities: [Emma, picture, mother]; Relations: [(Emma, painted, picture), (picture, for, mother)]\n",
        "\n",
        "Example 5:\n",
        "Input: The chef cooked dinner for the guests.\n",
        "Output: Entities: [chef, dinner, guests]; Relations: [(chef, cooked, dinner), (dinner, for, guests)]\n",
        "\n",
        "Example 6:\n",
        "Input: Sarah took her dog to the park.\n",
        "Output: Entities: [Sarah, dog, park]; Relations: [(Sarah, took, dog), (dog, to, park)]\n",
        "\n",
        "Example 7:\n",
        "Input: The scientist discovered a new element.\n",
        "Output: Entities: [scientist, element]; Relations: [(scientist, discovered, element)]\n",
        "\n",
        "Example 8:\n",
        "Input: Michael borrowed a pen from Lisa.\n",
        "Output: Entities: [Michael, pen, Lisa]; Relations: [(Michael, borrowed, pen), (pen, from, Lisa)]\n",
        "\n",
        "Example 9:\n",
        "Input: Lucy found a wallet on the ground.\n",
        "Output: Entities: [Lucy, wallet, ground]; Relations: [(Lucy, found, wallet), (wallet, on, ground)]\n",
        "\n",
        "Example 10:\n",
        "Input: The teacher assigned homework to the students.\n",
        "Output: Entities: [teacher, homework, students]; Relations: [(teacher, assigned, homework), (homework, to, students)]\n",
        "\n",
        "Example 11:\n",
        "Input: James bought a coffee for his friend.\n",
        "Output: Entities: [James, coffee, friend]; Relations: [(James, bought, coffee), (coffee, for, friend)]\n",
        "\n",
        "Example 12:\n",
        "Input: The doctor examined the patient with care.\n",
        "Output: Entities: [doctor, patient]; Relations: [(doctor, examined, patient)]\n",
        "\n",
        "Example 13:\n",
        "Input: Laura wrote a letter to her grandmother.\n",
        "Output: Entities: [Laura, letter, grandmother]; Relations: [(Laura, wrote, letter), (letter, to, grandmother)]\n",
        "\n",
        "Example 14:\n",
        "Input: David watched a movie with his brother.\n",
        "Output: Entities: [David, movie, brother]; Relations: [(David, watched, movie), (movie, with, brother)]\n",
        "\n",
        "Example 15:\n",
        "Input: The artist sketched a portrait of a landscape.\n",
        "Output: Entities: [artist, portrait, landscape]; Relations: [(artist, sketched, portrait), (portrait, of, landscape)]\n",
        "\n",
        "Example 16:\n",
        "Input: Anna traveled to Paris last year.\n",
        "Output: Entities: [Anna, Paris, year]; Relations: [(Anna, traveled to, Paris), (traveled, last, year)]\n",
        "\n",
        "Example 17:\n",
        "Input: Tom gifted a ring to his sister.\n",
        "Output: Entities: [Tom, ring, sister]; Relations: [(Tom, gifted, ring), (ring, to, sister)]\n",
        "\n",
        "Example 18:\n",
        "Input: The librarian organized the books on the shelves.\n",
        "Output: Entities: [librarian, books, shelves]; Relations: [(librarian, organized, books), (books, on, shelves)]\n",
        "\n",
        "Example 19:\n",
        "Input: Daniel shared his notes with his classmates.\n",
        "Output: Entities: [Daniel, notes, classmates]; Relations: [(Daniel, shared, notes), (notes, with, classmates)]\n",
        "\n",
        "Example 20:\n",
        "Input: Megan practiced piano at the music school.\n",
        "Output: Entities: [Megan, piano, music school]; Relations: [(Megan, practiced, piano), (piano, at, music school)]\n",
        "\n",
        "Now, for the following sentence:\n",
        "\n",
        "Input: At the science fair, Clara presented her project about renewable energy sources.\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "# Use the endpoint to generate the response\n",
        "response = llm(prompt)\n",
        "\n",
        "# Print the generated result\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "hKCGUJoPNKDZ",
        "outputId": "81b632f0-f583-4636-b70a-666d389cb0ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "Entities: [Clara, project, renewable energy sources, science fair]\n",
            "Relations: [(Clara, presented, project), (project, about, renewable energy sources), (presented, at, science fair)]\n"
          ]
        }
      ]
    }
  ]
}